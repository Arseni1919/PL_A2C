# My A2C implementation as PL system

## The Algorithm

From - [2 - A2C implementation from Deep-Reinforcement-Learning-Hands-On-Second-Edition (pages 315-317)](https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On-Second-Edition/blob/master/Chapter12/02_pong_a2c.py)

From a training point of view, we complete these steps:

![The Algorithm](pics/alg1.png)

The preceding algorithm is an outline and similar to those that are usually printed
in research papers. In practice, some considerations are as follows:


The separate parts:
- Data module
- Neural Nets
- PL module
- Callbacks
- Data set

## `LunarLander-v2` parameters:
```

```
A2C net:
```

```

## `CartPole-v0` parameters:
```

```
A2C net:
```

```

## Thanks to:

- [1 - Deriving Policy Gradients and Implementing REINFORCE](https://medium.com/@thechrisyoon/deriving-policy-gradients-and-implementing-reinforce-f887949bd63)
- [2 - A2C implementation from Deep-Reinforcement-Learning-Hands-On-Second-Edition (pages 315-317)](https://github.com/PacktPublishing/Deep-Reinforcement-Learning-Hands-On-Second-Edition/blob/master/Chapter12/02_pong_a2c.py)
- [A2C `higgsfield` implementation](https://github.com/higgsfield/RL-Adventure-2/blob/master/1.actor-critic.ipynb)
- [REINFORCE+A2C (google colab)](https://colab.research.google.com/github/yfletberliac/rlss-2019/blob/master/labs/DRL.01.REINFORCE%2BA2C.ipynb#scrollTo=aNH3udIuyFgK)
- [Chris Yoon](https://towardsdatascience.com/understanding-actor-critic-methods-931b97b6df3f)
